{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from main.utils import load_experiments\n",
    "import os\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-loading names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [ 'random', 'entropy', 'bald', 'badge', 'max_logdet_S', 'empirical_covariance']\n",
    "datasets = ['mnist', 'dirty_mnist', 'fashion_mnist', 'repeated_mnist', 'imagenet']\n",
    "\n",
    "# naming of methods\n",
    "method_names = {\n",
    "    'badge': 'BADGE',\n",
    "    'random': 'Random',\n",
    "    'entropy': 'Entropy',\n",
    "    'bald': 'BALD',\n",
    "    'max_logdet_S': 'Similarity Matrix',\n",
    "    'empirical_covariance': 'Empirical Covariance',\n",
    "    'similarity_kmeans': 'Similarity KMeans',\n",
    "}\n",
    "\n",
    "\n",
    "# naming of datasets\n",
    "dataset_names = {\n",
    "    'mnist': 'MNIST',\n",
    "    'fashion_mnist': 'Fashion-MNIST',\n",
    "    'dirty_mnist': 'Dirty-MNIST',\n",
    "    'repeated_mnist': 'Repeated-MNIST',\n",
    "    'imagenet': 'ImageNet',\n",
    "}\n",
    "\n",
    "n_seeds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    for dataset in datasets:\n",
    "        for j in range(n_seeds):\n",
    "            try:\n",
    "                path = f'{method}_{dataset}_20_to_200_B=10_{j + 1}'\n",
    "                df = load_experiments([path])\n",
    "            except FileNotFoundError:\n",
    "                print(f'File {path} not found')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for method in methods:\n",
    "    results[method] = {}\n",
    "    for dataset in datasets:\n",
    "        experiment_ids = [f'{method}_{dataset}_20_to_200_B=10_{i + 1}' for i in range(n_seeds)]\n",
    "        res = load_experiments(experiment_ids)\n",
    "        accuracies = [[result[1]['test_accs'] for result in res]]\n",
    "        results[method][dataset] = accuracies\n",
    "\n",
    "# put all results in a single dataframe\n",
    "data = []\n",
    "for method in methods:\n",
    "    for dataset in datasets:\n",
    "        for result in results[method][dataset]:\n",
    "            for j in range(n_seeds):\n",
    "                data.append({\n",
    "                    'method': method,\n",
    "                    'dataset': dataset,\n",
    "                    'seed': j,\n",
    "                    'accuracy': result[j][-1],\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns='dataset', inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['method'] = subset_ranktest['method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['test_method'] = subset_ranktest['test_method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns=['method', 'test_method'], inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns='dataset', inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['method'] = subset_ranktest['method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['test_method'] = subset_ranktest['test_method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns=['method', 'test_method'], inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns='dataset', inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['method'] = subset_ranktest['method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['test_method'] = subset_ranktest['test_method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns=['method', 'test_method'], inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns='dataset', inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['method'] = subset_ranktest['method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['test_method'] = subset_ranktest['test_method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns=['method', 'test_method'], inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns='dataset', inplace=True)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['method'] = subset_ranktest['method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest['test_method'] = subset_ranktest['test_method'].map(method_names)\n",
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\3835934084.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_ranktest.drop(columns=['method', 'test_method'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MNIST</th>\n",
       "      <th>Dirty-MNIST</th>\n",
       "      <th>Fashion-MNIST</th>\n",
       "      <th>Repeated-MNIST</th>\n",
       "      <th>ImageNet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Similarity Matrix vs Random</th>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empirical Covariance vs Random</th>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Similarity Matrix vs Entropy</th>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empirical Covariance vs Entropy</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Similarity Matrix vs BALD</th>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empirical Covariance vs BALD</th>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Similarity Matrix vs BADGE</th>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empirical Covariance vs BADGE</th>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Similarity Matrix vs Empirical Covariance</th>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             MNIST  Dirty-MNIST  \\\n",
       "Similarity Matrix vs Random                0.03125      0.03125   \n",
       "Empirical Covariance vs Random             0.03125      0.06250   \n",
       "Similarity Matrix vs Entropy               0.96875      0.03125   \n",
       "Empirical Covariance vs Entropy            0.78125      0.03125   \n",
       "Similarity Matrix vs BALD                  0.06250      0.03125   \n",
       "Empirical Covariance vs BALD               0.03125      0.03125   \n",
       "Similarity Matrix vs BADGE                 0.03125      0.03125   \n",
       "Empirical Covariance vs BADGE              0.03125      0.03125   \n",
       "Similarity Matrix vs Empirical Covariance  0.96875      0.09375   \n",
       "\n",
       "                                           Fashion-MNIST  Repeated-MNIST  \\\n",
       "Similarity Matrix vs Random                      0.68750         0.03125   \n",
       "Empirical Covariance vs Random                   0.90625         0.03125   \n",
       "Similarity Matrix vs Entropy                     0.03125         0.15625   \n",
       "Empirical Covariance vs Entropy                  0.21875         0.06250   \n",
       "Similarity Matrix vs BALD                        0.21875         0.15625   \n",
       "Empirical Covariance vs BALD                     0.50000         0.40625   \n",
       "Similarity Matrix vs BADGE                       0.84375         0.03125   \n",
       "Empirical Covariance vs BADGE                    0.93750         0.03125   \n",
       "Similarity Matrix vs Empirical Covariance        0.15625         0.40625   \n",
       "\n",
       "                                           ImageNet  \n",
       "Similarity Matrix vs Random                 0.03125  \n",
       "Empirical Covariance vs Random              0.50000  \n",
       "Similarity Matrix vs Entropy                0.03125  \n",
       "Empirical Covariance vs Entropy             1.00000  \n",
       "Similarity Matrix vs BALD                   0.06250  \n",
       "Empirical Covariance vs BALD                1.00000  \n",
       "Similarity Matrix vs BADGE                  0.03125  \n",
       "Empirical Covariance vs BADGE               0.84375  \n",
       "Similarity Matrix vs Empirical Covariance   0.03125  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon_results = {}\n",
    "\n",
    "# for each dataset, apply the Wilcoxon rank test to compare the methods\n",
    "for test_method in ['max_logdet_S', 'empirical_covariance']:\n",
    "    comp_methods = methods.copy()\n",
    "    comp_methods.remove(test_method)\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for i, method in enumerate(comp_methods):\n",
    "            test = stats.wilcoxon(df[(df['method'] == method) & (df['dataset'] == dataset)]['accuracy'],\n",
    "                                  df[(df['method'] == test_method) & (df['dataset'] == dataset)]['accuracy'],\n",
    "                                  alternative='less')\n",
    "            \n",
    "            if dataset not in wilcoxon_results:\n",
    "                wilcoxon_results[dataset] = {}\n",
    "            if method not in wilcoxon_results[dataset]:\n",
    "                wilcoxon_results[dataset][method] = {}\n",
    "            wilcoxon_results[dataset][method][test_method] = test\n",
    "\n",
    "# save the results in dataframe\n",
    "data = []\n",
    "for dataset in datasets:\n",
    "    for method in methods:\n",
    "        for test_method in ['max_logdet_S', 'empirical_covariance']:\n",
    "            if test_method == method:\n",
    "                continue\n",
    "            data.append({\n",
    "                'dataset': dataset,\n",
    "                'method': method,\n",
    "                'test_method': test_method,\n",
    "                'p_value': wilcoxon_results[dataset][method][test_method].pvalue,\n",
    "            })\n",
    "\n",
    "wilcoxon_results = pd.DataFrame(data)\n",
    "\n",
    "wilcoxon_final = []\n",
    "for data_set in datasets:\n",
    "\n",
    "    subset_ranktest = wilcoxon_results[wilcoxon_results['dataset'] == data_set]\n",
    "    subset_ranktest.drop(columns='dataset', inplace=True)\n",
    "\n",
    "    # replace the method names with the full names\n",
    "    subset_ranktest['method'] = subset_ranktest['method'].map(method_names)\n",
    "    subset_ranktest['test_method'] = subset_ranktest['test_method'].map(method_names)\n",
    "\n",
    "    subset_ranktest.index = subset_ranktest['test_method'] + ' vs ' +  subset_ranktest['method'] \n",
    "    subset_ranktest.drop(columns=['method', 'test_method'], inplace=True)\n",
    "    subset_ranktest.columns = [dataset_names[data_set]]\n",
    "\n",
    "    wilcoxon_final.append(subset_ranktest)\n",
    "\n",
    "wilcoxon_final = pd.concat(wilcoxon_final, axis=1)\n",
    "wilcoxon_final.drop(labels='Empirical Covariance vs Similarity Matrix', axis=0, inplace=True)\n",
    "wilcoxon_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedman + Nemenyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman Test Statistic: 25.571428571428555, p-value: 0.000108038898314909\n",
      "\n",
      "Nemenyi Post-hoc Test Results (p-values):\n",
      "method                   badge      bald  empirical_covariance   entropy  \\\n",
      "method                                                                     \n",
      "badge                 1.000000  0.766754              0.363156  0.900000   \n",
      "bald                  0.766754  1.000000              0.900000  0.900000   \n",
      "empirical_covariance  0.363156  0.900000              1.000000  0.679434   \n",
      "entropy               0.900000  0.900000              0.679434  1.000000   \n",
      "max_logdet_S          0.001613  0.104666              0.410222  0.011371   \n",
      "random                0.900000  0.410222              0.104666  0.854075   \n",
      "\n",
      "method                max_logdet_S    random  \n",
      "method                                        \n",
      "badge                     0.001613  0.900000  \n",
      "bald                      0.104666  0.410222  \n",
      "empirical_covariance      0.410222  0.104666  \n",
      "entropy                   0.011371  0.854075  \n",
      "max_logdet_S              1.000000  0.001000  \n",
      "random                    0.001000  1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_20308\\4253769244.py:26: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_nemenyi_df = nemenyi_df.style.applymap(highlight_significant)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76cf7_row0_col4, #T_76cf7_row3_col4, #T_76cf7_row4_col0, #T_76cf7_row4_col3, #T_76cf7_row4_col5, #T_76cf7_row5_col4 {\n",
       "  background-color: blue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76cf7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th id=\"T_76cf7_level0_col0\" class=\"col_heading level0 col0\" >badge</th>\n",
       "      <th id=\"T_76cf7_level0_col1\" class=\"col_heading level0 col1\" >bald</th>\n",
       "      <th id=\"T_76cf7_level0_col2\" class=\"col_heading level0 col2\" >empirical_covariance</th>\n",
       "      <th id=\"T_76cf7_level0_col3\" class=\"col_heading level0 col3\" >entropy</th>\n",
       "      <th id=\"T_76cf7_level0_col4\" class=\"col_heading level0 col4\" >max_logdet_S</th>\n",
       "      <th id=\"T_76cf7_level0_col5\" class=\"col_heading level0 col5\" >random</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76cf7_level0_row0\" class=\"row_heading level0 row0\" >badge</th>\n",
       "      <td id=\"T_76cf7_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_76cf7_row0_col1\" class=\"data row0 col1\" >0.766754</td>\n",
       "      <td id=\"T_76cf7_row0_col2\" class=\"data row0 col2\" >0.363156</td>\n",
       "      <td id=\"T_76cf7_row0_col3\" class=\"data row0 col3\" >0.900000</td>\n",
       "      <td id=\"T_76cf7_row0_col4\" class=\"data row0 col4\" >0.001613</td>\n",
       "      <td id=\"T_76cf7_row0_col5\" class=\"data row0 col5\" >0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cf7_level0_row1\" class=\"row_heading level0 row1\" >bald</th>\n",
       "      <td id=\"T_76cf7_row1_col0\" class=\"data row1 col0\" >0.766754</td>\n",
       "      <td id=\"T_76cf7_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_76cf7_row1_col2\" class=\"data row1 col2\" >0.900000</td>\n",
       "      <td id=\"T_76cf7_row1_col3\" class=\"data row1 col3\" >0.900000</td>\n",
       "      <td id=\"T_76cf7_row1_col4\" class=\"data row1 col4\" >0.104666</td>\n",
       "      <td id=\"T_76cf7_row1_col5\" class=\"data row1 col5\" >0.410222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cf7_level0_row2\" class=\"row_heading level0 row2\" >empirical_covariance</th>\n",
       "      <td id=\"T_76cf7_row2_col0\" class=\"data row2 col0\" >0.363156</td>\n",
       "      <td id=\"T_76cf7_row2_col1\" class=\"data row2 col1\" >0.900000</td>\n",
       "      <td id=\"T_76cf7_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_76cf7_row2_col3\" class=\"data row2 col3\" >0.679434</td>\n",
       "      <td id=\"T_76cf7_row2_col4\" class=\"data row2 col4\" >0.410222</td>\n",
       "      <td id=\"T_76cf7_row2_col5\" class=\"data row2 col5\" >0.104666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cf7_level0_row3\" class=\"row_heading level0 row3\" >entropy</th>\n",
       "      <td id=\"T_76cf7_row3_col0\" class=\"data row3 col0\" >0.900000</td>\n",
       "      <td id=\"T_76cf7_row3_col1\" class=\"data row3 col1\" >0.900000</td>\n",
       "      <td id=\"T_76cf7_row3_col2\" class=\"data row3 col2\" >0.679434</td>\n",
       "      <td id=\"T_76cf7_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_76cf7_row3_col4\" class=\"data row3 col4\" >0.011371</td>\n",
       "      <td id=\"T_76cf7_row3_col5\" class=\"data row3 col5\" >0.854075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cf7_level0_row4\" class=\"row_heading level0 row4\" >max_logdet_S</th>\n",
       "      <td id=\"T_76cf7_row4_col0\" class=\"data row4 col0\" >0.001613</td>\n",
       "      <td id=\"T_76cf7_row4_col1\" class=\"data row4 col1\" >0.104666</td>\n",
       "      <td id=\"T_76cf7_row4_col2\" class=\"data row4 col2\" >0.410222</td>\n",
       "      <td id=\"T_76cf7_row4_col3\" class=\"data row4 col3\" >0.011371</td>\n",
       "      <td id=\"T_76cf7_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_76cf7_row4_col5\" class=\"data row4 col5\" >0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76cf7_level0_row5\" class=\"row_heading level0 row5\" >random</th>\n",
       "      <td id=\"T_76cf7_row5_col0\" class=\"data row5 col0\" >0.900000</td>\n",
       "      <td id=\"T_76cf7_row5_col1\" class=\"data row5 col1\" >0.410222</td>\n",
       "      <td id=\"T_76cf7_row5_col2\" class=\"data row5 col2\" >0.104666</td>\n",
       "      <td id=\"T_76cf7_row5_col3\" class=\"data row5 col3\" >0.854075</td>\n",
       "      <td id=\"T_76cf7_row5_col4\" class=\"data row5 col4\" >0.001000</td>\n",
       "      <td id=\"T_76cf7_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244828d4cb0>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape DataFrame for the Friedman Test\n",
    "pivot_df = df.pivot_table(index=['dataset', 'seed'], columns='method', values='accuracy')\n",
    "\n",
    "# Perform Friedman Test\n",
    "friedman_stat, p_value = friedmanchisquare(*[pivot_df[method] for method in pivot_df.columns])\n",
    "\n",
    "print(f\"Friedman Test Statistic: {friedman_stat}, p-value: {p_value}\")\n",
    "\n",
    "# Perform Nemenyi Post-hoc Test\n",
    "nemenyi_results = sp.posthoc_nemenyi_friedman(pivot_df.values)\n",
    "\n",
    "# Format Nemenyi test results\n",
    "method_names = pivot_df.columns\n",
    "nemenyi_df = pd.DataFrame(nemenyi_results)\n",
    "nemenyi_df.columns = method_names\n",
    "nemenyi_df.index = method_names\n",
    "\n",
    "# Output Nemenyi test results\n",
    "print(\"\\nNemenyi Post-hoc Test Results (p-values):\")\n",
    "print(nemenyi_df)\n",
    "\n",
    "# Highlight significant results\n",
    "def highlight_significant(p):\n",
    "    return 'background-color: blue' if p < 0.05 else ''\n",
    "\n",
    "styled_nemenyi_df = nemenyi_df.style.applymap(highlight_significant)\n",
    "\n",
    "# Display styled DataFrame\n",
    "styled_nemenyi_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
