{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Experiment.\n",
    "Modular setup of the AL experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import laplace\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from batchbald_redux import repeated_mnist, active_learning, batchbald\n",
    "from main.models import BayesianConvNet, ConvNet\n",
    "from main.training_models import test_performance\n",
    "from main.utils import save_experiment, load_experiment\n",
    "from laplace.curvature import AsdlGGN, AsdlGGN\n",
    "from main.laplace_batch import get_laplace_batch\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "train_dataset, test_dataset = repeated_mnist.create_MNIST_dataset()\n",
    "\n",
    "# number of initial samples \n",
    "num_initial_samples = 40\n",
    "num_classes = 10\n",
    "\n",
    "# get indices of initial samples\n",
    "initial_samples = active_learning.get_balanced_sample_indices(\n",
    "    repeated_mnist.get_targets(train_dataset), num_classes=num_classes, n_per_digit=num_initial_samples / num_classes\n",
    ")\n",
    "\n",
    "# Experiment parameters\n",
    "\n",
    "## Active learning parameters\n",
    "max_training_samples = 100  # Maximum number of samples to acquire from the pool dataset \n",
    "acquisition_batch_size = 5 # Number of samples to acquire in each acquisition step\n",
    "\n",
    "## Training parameters\n",
    "test_batch_size = 512  # Batch size for testing\n",
    "batch_size = 64  # Batch size for training\n",
    "scoring_batch_size = 64  # Batch size for scoring \n",
    "training_iterations_nn = 4096 * 6 # Number of training iterations (batches) to run\n",
    "training_iterations_la = 4096 * 6  # Number of training iterations (batches) to run\n",
    "\n",
    "## Model parameters\n",
    "hessian_structure = \"kron\"  # Options: \"full\", \"kron\", \"lowrank\" and \"diag\"\n",
    "subset_of_weights = \"last_layer\"  # Options: \"all\", \"subnetwork\" and \"last_layer\"\n",
    "backend = AsdlGGN  # Options: CurvlinopsGGN, CurvlinopsEF, AsdlEF, AsdlGGN, BackPackGGN\n",
    "al_method = 'max_logdet_S'  # Options: \"logit_entropy\", \"probit_entropy\", \"entropy\", \"bald\"\n",
    "temperature = 1  # Temperature for LA model\n",
    "\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "\n",
    "print(f\"use_cuda: {use_cuda}\")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "active_learning_data = active_learning.ActiveLearningData(train_dataset)\n",
    "\n",
    "# Split off the initial samples first.\n",
    "active_learning_data.acquire(initial_samples)\n",
    "\n",
    "# THIS REMOVES MOST OF THE POOL DATA. UNCOMMENT THIS TO TAKE ALL UNLABELLED DATA INTO ACCOUNT!\n",
    "active_learning_data.extract_dataset_from_pool(55000)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.training_dataset,\n",
    "    sampler=active_learning.RandomFixedLengthSampler(active_learning_data.training_dataset, training_iterations_nn),\n",
    "    batch_size=batch_size,\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "pool_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.pool_dataset, batch_size=scoring_batch_size, shuffle=False, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 2.2790260314941406\n",
      "Epoch 6/40, Loss: 1.4461164474487305\n",
      "Epoch 11/40, Loss: 0.47085005044937134\n",
      "Epoch 16/40, Loss: 0.16333997249603271\n",
      "Epoch 21/40, Loss: 0.03856278955936432\n",
      "Epoch 26/40, Loss: 0.024504441767930984\n",
      "Epoch 31/40, Loss: 0.005573248490691185\n",
      "Epoch 36/40, Loss: 0.004476090893149376\n",
      "Accuracy of the network on the test data: 76.48%\n",
      "Epoch 1/40, Loss: 2.2760512828826904\n",
      "Epoch 6/40, Loss: 1.2796940803527832\n",
      "Epoch 11/40, Loss: 0.43450281023979187\n",
      "Epoch 16/40, Loss: 0.11711275577545166\n",
      "Epoch 21/40, Loss: 0.06586829572916031\n",
      "Epoch 26/40, Loss: 0.018535656854510307\n",
      "Epoch 31/40, Loss: 0.007437944412231445\n",
      "Epoch 36/40, Loss: 0.004991069436073303\n",
      "Accuracy of the network on the test data: 75.64%\n",
      "Epoch 1/40, Loss: 2.2653181552886963\n",
      "Epoch 6/40, Loss: 1.5990852117538452\n",
      "Epoch 11/40, Loss: 0.7037209272384644\n",
      "Epoch 16/40, Loss: 0.18051743507385254\n",
      "Epoch 21/40, Loss: 0.02560562826693058\n",
      "Epoch 26/40, Loss: 0.01870080456137657\n",
      "Epoch 31/40, Loss: 0.005936708301305771\n",
      "Epoch 36/40, Loss: 0.005331915803253651\n",
      "Accuracy of the network on the test data: 73.9%\n",
      "Epoch 1/40, Loss: 2.327610492706299\n",
      "Epoch 6/40, Loss: 1.385093331336975\n",
      "Epoch 11/40, Loss: 0.4042610228061676\n",
      "Epoch 16/40, Loss: 0.10789990425109863\n",
      "Epoch 21/40, Loss: 0.03873263671994209\n",
      "Epoch 26/40, Loss: 0.009105720557272434\n",
      "Epoch 31/40, Loss: 0.005629140418022871\n",
      "Epoch 36/40, Loss: 0.0023405207321047783\n",
      "Accuracy of the network on the test data: 76.43%\n",
      "Epoch 1/40, Loss: 2.263305902481079\n",
      "Epoch 6/40, Loss: 1.436004400253296\n",
      "Epoch 11/40, Loss: 0.3768053650856018\n",
      "Epoch 16/40, Loss: 0.10550957173109055\n",
      "Epoch 21/40, Loss: 0.027417533099651337\n",
      "Epoch 26/40, Loss: 0.013651680201292038\n",
      "Epoch 31/40, Loss: 0.005392016377300024\n",
      "Epoch 36/40, Loss: 0.003228412941098213\n",
      "Accuracy of the network on the test data: 75.07%\n",
      "Epoch 1/40, Loss: 2.2939705848693848\n",
      "Epoch 6/40, Loss: 1.602657675743103\n",
      "Epoch 11/40, Loss: 0.41342729330062866\n",
      "Epoch 16/40, Loss: 0.13822567462921143\n",
      "Epoch 21/40, Loss: 0.05057340860366821\n",
      "Epoch 26/40, Loss: 0.013358499854803085\n",
      "Epoch 31/40, Loss: 0.009300670586526394\n",
      "Epoch 36/40, Loss: 0.002290688920766115\n",
      "Accuracy of the network on the test data: 75.49%\n",
      "Epoch 1/40, Loss: 2.3013436794281006\n",
      "Epoch 6/40, Loss: 1.602205753326416\n",
      "Epoch 11/40, Loss: 0.7028272151947021\n",
      "Epoch 16/40, Loss: 0.2877252697944641\n",
      "Epoch 21/40, Loss: 0.05280983820557594\n",
      "Epoch 26/40, Loss: 0.019509391859173775\n",
      "Epoch 31/40, Loss: 0.012633712030947208\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_loader_benchmark \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      2\u001b[0m                                                      sampler\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubsetRandomSampler(\u001b[38;5;28mrange\u001b[39m(max_training_samples)))\n\u001b[1;32m----> 3\u001b[0m accs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConvNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_benchmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial performance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mmean(accs)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mstd(accs)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\main\\training_models.py:44\u001b[0m, in \u001b[0;36mtest_performance\u001b[1;34m(model_constructor, train_loader, test_loader, repeats)\u001b[0m\n\u001b[0;32m     41\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeats):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# test model\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\main\\training_models.py:15\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, num_epochs, lr, reg_lambda, opt_params, verbose)\u001b[0m\n\u001b[0;32m     12\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m num_epochs\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# forward pass\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:920\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    918\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    919\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader_benchmark = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                                     sampler=torch.utils.data.SubsetRandomSampler(range(max_training_samples)))\n",
    "accs = test_performance(ConvNet, train_loader_benchmark, test_loader, repeats=10)\n",
    "print(f\"Initial performance: {torch.mean(accs):.3f} +- {torch.std(accs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set Size:  40%|████      | 40/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: -0.0176, Accuracy: 7304/10000 (73.04%)\n",
      "Fitting Laplace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\laplace\\baselaplace.py:409: UserWarning: By default `link_approx` is `probit`. Make sure to set it equals to the way you want to call `la(test_data, pred_type=..., link_approx=...)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing prior precision\n",
      "Optimized prior precision is tensor([60.5140]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set Size:  45%|████▌     | 45/100 [01:24<15:26, 16.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [ 7579 32980 58633 10859 21595]\n",
      "Scores:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Labels:  tensor([4, 7, 5, 0, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: -0.0169, Accuracy: 7386/10000 (73.86%)\n",
      "Fitting Laplace\n",
      "Optimizing prior precision\n",
      "Optimized prior precision is tensor([57.3871]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set Size:  50%|█████     | 50/100 [02:39<13:07, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [27885 12798 58024 50620 30696]\n",
      "Scores:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Labels:  tensor([1, 1, 8, 7, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: -0.0250, Accuracy: 7413/10000 (74.13%)\n",
      "Fitting Laplace\n",
      "Optimizing prior precision\n",
      "Optimized prior precision is tensor([61.4044]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set Size:  55%|█████▌    | 55/100 [03:54<11:34, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [23705 50510 49065 54920 57443]\n",
      "Scores:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Labels:  tensor([2, 4, 0, 8, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTesting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:1083\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m   1080\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m   1081\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1083\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\connection.py:1015\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m   1013\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "test_accs = []\n",
    "test_loss = []\n",
    "added_indices = []\n",
    "added_labels = []\n",
    "\n",
    "pbar = tqdm(initial=len(active_learning_data.training_dataset), total=max_training_samples, desc=\"Training Set Size\")\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "while True:\n",
    "    model = ConvNet().to(device=device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Train\n",
    "    for data, target in tqdm(train_loader_nn, desc=\"Training\", leave=False):\n",
    "        data = data.to(device=device)\n",
    "        target = target.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = F.log_softmax(model(data).squeeze(1), dim=1)\n",
    "        loss = loss_fn(prediction, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "\n",
    "            prediction = model(data).squeeze(1)\n",
    "            loss += loss_fn(prediction, target)\n",
    "\n",
    "            prediction = prediction.argmax(dim=1)\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    loss /= len(test_loader.dataset)\n",
    "    test_loss.append(loss)\n",
    "\n",
    "    percentage_correct = 100.0 * correct / len(test_loader.dataset)\n",
    "    test_accs.append(percentage_correct)\n",
    "\n",
    "    print(\n",
    "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(\n",
    "            loss, correct, len(test_loader.dataset), percentage_correct\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if len(active_learning_data.training_dataset) >= max_training_samples:\n",
    "        break\n",
    "\n",
    "    # Acquire new batch from pool samples using entropy acquisition function\n",
    "    N = len(active_learning_data.pool_dataset)\n",
    "    \n",
    "    la = laplace.Laplace(\n",
    "                        model,\n",
    "                        likelihood=\"classification\",\n",
    "                        subset_of_weights=subset_of_weights,\n",
    "                        hessian_structure=hessian_structure,\n",
    "                        backend=backend,\n",
    "                        temperature=temperature/len(active_learning_data.training_dataset),\n",
    "                     )\n",
    "    \n",
    "    print('Fitting Laplace')\n",
    "    la.fit(train_loader_la, progress_bar=True)\n",
    "\n",
    "    print('Optimizing prior precision')\n",
    "    la.optimize_prior_precision(method='marglik', verbose=True, pred_type='glm', link_approx='probit')\n",
    "    \n",
    "    candidate_batch = get_laplace_batch(model=la, pool_loader=pool_loader,\n",
    "                                            acquisition_batch_size=acquisition_batch_size,\n",
    "                                            device=device, \n",
    "                                            method=al_method)\n",
    "\n",
    "\n",
    "    targets = repeated_mnist.get_targets(active_learning_data.pool_dataset)\n",
    "    dataset_indices = active_learning_data.get_dataset_indices(candidate_batch.indices)\n",
    "\n",
    "    print(\"Dataset indices: \", dataset_indices)\n",
    "    print(\"Scores: \", candidate_batch.scores)\n",
    "    print(\"Labels: \", targets[candidate_batch.indices])\n",
    "\n",
    "    active_learning_data.acquire(candidate_batch.indices)\n",
    "    added_indices.append(dataset_indices)\n",
    "    added_labels.append(targets[candidate_batch.indices])\n",
    "    pbar.update(len(dataset_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = np.random.randint(1000, 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'num_initial_samples': num_initial_samples,\n",
    "    'num_classes': num_classes,\n",
    "    'max_training_samples': max_training_samples,\n",
    "    'acquisition_batch_size': acquisition_batch_size,\n",
    "    'test_batch_size': test_batch_size,\n",
    "    'batch_size': batch_size,\n",
    "    'scoring_batch_size': scoring_batch_size,\n",
    "    'training_iterations_nn': training_iterations_nn,\n",
    "    'training_iterations_la': training_iterations_la,\n",
    "}\n",
    "\n",
    "# generate a unique experiment id of 3 digits (just to make sure don't override things, clean up later)\n",
    "save_experiment(f'{al_method}_{hessian_structure}_{subset_of_weights}_K{acquisition_batch_size}_{experiment_id}',\n",
    "                params_dict, {\n",
    "    'test_accs': test_accs,\n",
    "    'test_loss': test_loss,\n",
    "    'added_indices': added_indices\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(start=num_initial_samples, stop=max_training_samples + acquisition_batch_size, step=acquisition_batch_size), test_accs)\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.hlines(90, num_initial_samples, max_training_samples, colors='r', linestyles='dashed')\n",
    "plt.savefig(f'plots/{al_method}_{hessian_structure}_{subset_of_weights}_K{acquisition_batch_size}_{experiment_id}.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
