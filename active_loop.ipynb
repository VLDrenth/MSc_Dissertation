{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from batchbald_redux import repeated_mnist, active_learning, batchbald\n",
    "from main.models import ConvNet\n",
    "from main.training_models import test_performance\n",
    "from main.utils import save_experiment, load_experiment, log_experiment, generate_experiment_id\n",
    "from laplace.curvature import AsdlGGN, AsdlGGN\n",
    "from main.laplace_batch import get_laplace_batch\n",
    "from dataclasses import dataclass\n",
    "from main.active_learning import run_active_learning\n",
    "\n",
    "sns.set_palette(sns.color_palette(\"Spectral\"))\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# set configurations\n",
    "@dataclass\n",
    "class ActiveLearningConfig:\n",
    "    subset_of_weights: str = 'last_layer'\n",
    "    hessian_structure: str = 'kron'\n",
    "    backend: str = 'AsdlGGN'\n",
    "    temperature: float = 1\n",
    "    max_training_samples: int = 100\n",
    "    acquisition_batch_size: int = 5\n",
    "    al_method: str = 'entropy'\n",
    "    test_batch_size: int = 512\n",
    "    num_classes: int = 10\n",
    "    num_initial_samples: int = 40\n",
    "    training_iterations: int = 4096 * 6\n",
    "    scoring_batch_size: int = 64\n",
    "    train_batch_size: int = 64\n",
    "    extract_pool: int = 55000  # number of samples to extract from the dataset (bit of a hack)\n",
    "\n",
    "experiment_name = 'lowtemperature_'  # provide descriptive name for the experiment\n",
    "experiment_name += generate_experiment_id()\n",
    "\n",
    "config = ActiveLearningConfig()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "\n",
    "save_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "train_dataset, test_dataset = repeated_mnist.create_MNIST_dataset()\n",
    "\n",
    "# get indices of initial samples\n",
    "initial_samples = active_learning.get_balanced_sample_indices(\n",
    "    repeated_mnist.get_targets(train_dataset), num_classes=config.num_classes, n_per_digit=config.num_initial_samples / config.num_classes\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "active_learning_data = active_learning.ActiveLearningData(train_dataset)\n",
    "\n",
    "# Split off the initial samples first.\n",
    "active_learning_data.acquire(initial_samples)\n",
    "\n",
    "# THIS REMOVES MOST OF THE POOL DATA. REMOVE THIS LINE TO USE THE FULL POOL\n",
    "active_learning_data.extract_dataset_from_pool(config.extract_pool)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.training_dataset,\n",
    "    sampler=active_learning.RandomFixedLengthSampler(active_learning_data.training_dataset, config.training_iterations),\n",
    "    batch_size=config.train_batch_size,\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "pool_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.pool_dataset, batch_size=config.scoring_batch_size, shuffle=False, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Active Learning with settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Set Size:  40%|████      | 40/100 [00:00<?, ?it/s]2024-07-28 11:14:36,897 - INFO - Training set size: 40, Test set accuracy: 76.53, Test set loss: -0.0117\n",
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "c:\\Users\\vince\\Documents\\Statistics\\TT\\msc_thesis\\.venv\\Lib\\site-packages\\laplace\\baselaplace.py:409: UserWarning: By default `link_approx` is `probit`. Make sure to set it equals to the way you want to call `la(test_data, pred_type=..., link_approx=...)`.\n",
      "  warnings.warn(\n",
      "Computing entropies: 78it [00:04, 17.98it/s]\n",
      "Training Set Size:  45%|████▌     | 45/100 [00:35<06:29,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [26852  8713 13063  1804 56874]\n",
      "Scores:  [1.9689174890518188, 1.9535801410675049, 1.9389352798461914, 1.9305953979492188, 1.9218602180480957]\n",
      "Labels:  tensor([8, 5, 9, 8, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:15:15,546 - INFO - Training set size: 45, Test set accuracy: 77.00, Test set loss: -0.0225\n",
      "Computing entropies: 78it [00:04, 15.73it/s]\n",
      "Training Set Size:  50%|█████     | 50/100 [01:15<06:22,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [48680 12076 12359 32012  8786]\n",
      "Scores:  [1.9359958171844482, 1.6774601936340332, 1.6574766635894775, 1.6573704481124878, 1.6566517353057861]\n",
      "Labels:  tensor([5, 9, 6, 8, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:15:53,676 - INFO - Training set size: 50, Test set accuracy: 79.31, Test set loss: -0.0166\n",
      "Computing entropies: 78it [00:04, 16.19it/s]\n",
      "Training Set Size:  55%|█████▌    | 55/100 [01:52<05:37,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [49302  3104 30159 26981 32524]\n",
      "Scores:  [1.8859899044036865, 1.8834879398345947, 1.8813992738723755, 1.8368420600891113, 1.8345773220062256]\n",
      "Labels:  tensor([8, 9, 3, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:16:29,306 - INFO - Training set size: 55, Test set accuracy: 82.56, Test set loss: -0.0244\n",
      "Computing entropies: 78it [00:04, 18.16it/s]\n",
      "Training Set Size:  60%|██████    | 60/100 [02:26<04:50,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [44250 51283 37341 49012 30485]\n",
      "Scores:  [1.6477454900741577, 1.6442286968231201, 1.6419825553894043, 1.6105098724365234, 1.59601628780365]\n",
      "Labels:  tensor([6, 5, 5, 7, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:17:04,536 - INFO - Training set size: 60, Test set accuracy: 79.98, Test set loss: -0.0243\n",
      "Computing entropies: 78it [00:04, 17.67it/s]\n",
      "Training Set Size:  65%|██████▌   | 65/100 [03:02<04:12,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [53696 48010 13081 25429 22147]\n",
      "Scores:  [2.0079548358917236, 1.9639463424682617, 1.931840181350708, 1.9001073837280273, 1.8774399757385254]\n",
      "Labels:  tensor([5, 7, 0, 8, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:17:40,184 - INFO - Training set size: 65, Test set accuracy: 82.69, Test set loss: -0.0303\n",
      "Computing entropies: 78it [00:04, 17.47it/s]\n",
      "Training Set Size:  70%|███████   | 70/100 [03:38<03:37,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [24633 16797 41611 37005 31962]\n",
      "Scores:  [1.965768575668335, 1.9328879117965698, 1.92270028591156, 1.9129570722579956, 1.9026795625686646]\n",
      "Labels:  tensor([2, 8, 8, 8, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:18:16,124 - INFO - Training set size: 70, Test set accuracy: 79.37, Test set loss: -0.0290\n",
      "Computing entropies: 78it [00:04, 17.22it/s]\n",
      "Training Set Size:  75%|███████▌  | 75/100 [04:14<02:59,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [25576 23578 57597 14295 11391]\n",
      "Scores:  [1.9196363687515259, 1.907682180404663, 1.9068281650543213, 1.8995343446731567, 1.875787615776062]\n",
      "Labels:  tensor([0, 2, 2, 2, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:18:51,583 - INFO - Training set size: 75, Test set accuracy: 82.79, Test set loss: -0.0242\n",
      "Computing entropies: 77it [00:04, 17.59it/s]\n",
      "Training Set Size:  80%|████████  | 80/100 [04:49<02:23,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [49009  9924 12812 49002 27822]\n",
      "Scores:  [1.8265278339385986, 1.8036136627197266, 1.7363224029541016, 1.7327243089675903, 1.7306407690048218]\n",
      "Labels:  tensor([2, 8, 3, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:19:27,706 - INFO - Training set size: 80, Test set accuracy: 81.00, Test set loss: -0.0323\n",
      "Computing entropies: 77it [00:05, 15.24it/s]\n",
      "Training Set Size:  85%|████████▌ | 85/100 [05:26<01:48,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [ 1088 55244 55064 19934  5381]\n",
      "Scores:  [1.6665570735931396, 1.6560964584350586, 1.6349788904190063, 1.6254900693893433, 1.607519268989563]\n",
      "Labels:  tensor([7, 7, 9, 9, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:20:05,104 - INFO - Training set size: 85, Test set accuracy: 82.86, Test set loss: -0.0233\n",
      "Computing entropies: 77it [00:04, 16.26it/s]\n",
      "Training Set Size:  90%|█████████ | 90/100 [06:04<01:13,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [39834 31339 33369 30139 33581]\n",
      "Scores:  [1.717010736465454, 1.7047741413116455, 1.696811556816101, 1.6967148780822754, 1.6739047765731812]\n",
      "Labels:  tensor([9, 6, 1, 6, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:20:42,566 - INFO - Training set size: 90, Test set accuracy: 83.68, Test set loss: -0.0266\n",
      "Computing entropies: 77it [00:04, 17.16it/s]\n",
      "Training Set Size:  95%|█████████▌| 95/100 [06:40<00:36,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [13997 14355 36760 11536 41283]\n",
      "Scores:  [1.7375097274780273, 1.7242283821105957, 1.7170239686965942, 1.690377116203308, 1.6881840229034424]\n",
      "Labels:  tensor([9, 2, 7, 9, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:21:18,216 - INFO - Training set size: 95, Test set accuracy: 83.04, Test set loss: -0.0249\n",
      "Computing entropies: 77it [00:04, 16.78it/s]\n",
      "Training Set Size: 100%|██████████| 100/100 [07:17<00:00,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [38631  9860 24587  1724 14124]\n",
      "Scores:  [1.6712132692337036, 1.629883885383606, 1.543965458869934, 1.4847278594970703, 1.471351981163025]\n",
      "Labels:  tensor([4, 6, 8, 2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:21:56,252 - INFO - Training set size: 100, Test set accuracy: 79.66, Test set loss: -0.0177\n",
      "Training Set Size: 100%|██████████| 100/100 [07:34<00:00,  7.57s/it]\n"
     ]
    }
   ],
   "source": [
    "results = run_active_learning(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader, \n",
    "    pool_loader=pool_loader,\n",
    "    active_learning_data=active_learning_data,\n",
    "    model_constructor=ConvNet, \n",
    "    config=config, \n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(start\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_initial_samples, stop\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_training_samples \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, step\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39macquisition_batch_size),\n\u001b[1;32m----> 2\u001b[0m             y\u001b[38;5;241m=\u001b[39m\u001b[43mresults\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActive Learning Performance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of training samples\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lineplot(x=np.arange(start=config.num_initial_samples, stop=config.max_training_samples + 1, step=config.acquisition_batch_size),\n",
    "            y=results['test_accs'])\n",
    "plt.title('Active Learning Performance')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Test Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment saved in experiments\\temperature_20240728-111421\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    save_experiment(config, results, experiment_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
