{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from batchbald_redux import repeated_mnist, active_learning, batchbald\n",
    "from main.models import ConvNet\n",
    "from main.training_models import test_performance\n",
    "from main.utils import save_experiment, load_experiment, log_experiment, generate_experiment_id\n",
    "from laplace.curvature import AsdlGGN, AsdlGGN\n",
    "from main.laplace_batch import get_laplace_batch\n",
    "from dataclasses import dataclass\n",
    "from main.active_learning import run_active_learning\n",
    "\n",
    "sns.set_palette(sns.color_palette(\"Spectral\"))\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configurations\n",
    "@dataclass\n",
    "class ActiveLearningConfig:\n",
    "    subset_of_weights: str = 'last_layer'\n",
    "    hessian_structure: str = 'kron'\n",
    "    backend: str = 'AsdlGGN'\n",
    "    temperature: float = 1.0\n",
    "    max_training_samples: int = 100\n",
    "    acquisition_batch_size: int = 5\n",
    "    al_method: str = 'entropy'\n",
    "    test_batch_size: int = 512\n",
    "    num_classes: int = 10\n",
    "    num_initial_samples: int = 40\n",
    "    training_iterations: int = 4096 // 64\n",
    "    scoring_batch_size: int = 64\n",
    "    train_batch_size: int = 64\n",
    "    extract_pool: int = 59900\n",
    "\n",
    "experiment_name = 'active_learning'  # provide descriptive name for the experiment\n",
    "experiment_name += generate_experiment_id()\n",
    "\n",
    "config = ActiveLearningConfig()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "save_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "train_dataset, test_dataset = repeated_mnist.create_MNIST_dataset()\n",
    "\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "\n",
    "# get indices of initial samples\n",
    "initial_samples = active_learning.get_balanced_sample_indices(\n",
    "    repeated_mnist.get_targets(train_dataset), num_classes=config.num_classes, n_per_digit=config.num_initial_samples / config.num_classes\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "active_learning_data = active_learning.ActiveLearningData(train_dataset)\n",
    "\n",
    "# Split off the initial samples first.\n",
    "active_learning_data.acquire(initial_samples)\n",
    "\n",
    "# THIS REMOVES MOST OF THE POOL DATA. REMOVE THIS LINE TO USE THE FULL POOL\n",
    "active_learning_data.extract_dataset_from_pool(config.extract_pool)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.training_dataset,\n",
    "    sampler=active_learning.RandomFixedLengthSampler(active_learning_data.training_dataset, config.training_iterations),\n",
    "    batch_size=config.train_batch_size,\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "pool_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.pool_dataset, batch_size=config.scoring_batch_size, shuffle=False, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Active Learning with settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_active_learning(\n",
    "    train_loader=traind_loader,\n",
    "    test_loader=test_loader, \n",
    "    active_learning_data=active_learning_data,\n",
    "    model_constructor=ConvNet, \n",
    "    config=config, \n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(start=config.num_initial_samples, stop=config.max_training_samples + 1, step=config.acquisition_batch_size),\n",
    "            y=results['test_accs'])\n",
    "plt.title('Active Learning Performance')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.stack(results['added_labels'])\n",
    "\n",
    "# give counts for each class\n",
    "counts = torch.zeros(config.num_classes)\n",
    "for i in range(config.num_classes):\n",
    "    counts[i] = (labels == i).sum()\n",
    "\n",
    "sns.barplot(x=np.arange(config.num_classes), y=counts)\n",
    "plt.title('Class distribution of added samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    save_experiment(config, results, experiment_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
